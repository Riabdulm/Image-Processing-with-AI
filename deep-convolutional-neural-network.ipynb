{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importation of needed Libraries**","metadata":{}},{"cell_type":"code","source":"from time import time\nimport logging\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\n\nprint(__doc__)\n\n# Display progress logs on stdout\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')","metadata":{"execution":{"iopub.status.busy":"2022-11-09T01:41:48.135134Z","iopub.execute_input":"2022-11-09T01:41:48.135590Z","iopub.status.idle":"2022-11-09T01:41:49.623050Z","shell.execute_reply.started":"2022-11-09T01:41:48.135427Z","shell.execute_reply":"2022-11-09T01:41:49.621757Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Automatically created module for IPython interactive environment\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Dataset Importaion and Processing**\n\nThe dataset - lfw_people were imported from sklearn.datasets. The label to predict is the identity of the individuals in the image (image recognition).","metadata":{}},{"cell_type":"code","source":"# Downloading and loading the dataset as numpy arrays\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n\n\n# introspect the images arrays to find the shapes (for plotting)\nn_samples, h, w = lfw_people.images.shape\n\n# for machine learning we use the 2 data directly (as relative pixel positions info is ignored by this model)\nX = lfw_people.data\nn_features = X.shape[1]\n\n# the label to predict is the id of the person\ny = lfw_people.target\ntarget_names = lfw_people.target_names\nn_classes = target_names.shape[0]\n\nprint(\"Total dataset size:\")\nprint(\"n_samples: %d\" % n_samples)\nprint(\"n_features: %d\" % n_features)\nprint(\"n_classes: %d\" % n_classes)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T01:41:49.625556Z","iopub.execute_input":"2022-11-09T01:41:49.625915Z","iopub.status.idle":"2022-11-09T01:42:38.395185Z","shell.execute_reply.started":"2022-11-09T01:41:49.625860Z","shell.execute_reply":"2022-11-09T01:42:38.393985Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Total dataset size:\nn_samples: 1288\nn_features: 1850\nn_classes: 7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Splitting data into a training set and a test set with test_size of 25%, and printing the resulting input variables X**","metadata":{}},{"cell_type":"code","source":"# split into a training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\nprint(X_test.shape)\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T01:42:38.396818Z","iopub.execute_input":"2022-11-09T01:42:38.397108Z","iopub.status.idle":"2022-11-09T01:42:38.410927Z","shell.execute_reply.started":"2022-11-09T01:42:38.397074Z","shell.execute_reply":"2022-11-09T01:42:38.409921Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(322, 1850)\n(966, 1850)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Setting parameters for the learner (Deep Convolutional Neural Network - CNN).**","metadata":{}},{"cell_type":"code","source":"#Import needed libraries\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nX_train = X_train.reshape(len(X_train), 50, 37, 1)        #50 * 37 to add up to 1850\nX_test = X_test.reshape(len(X_test), 50, 37, 1)\n\nprint(\"Fitting the CNN to the training set\")\n\nt0 = time()\n \noutput_classes = 7\n\nmodel=keras.Sequential([\n    keras.Input(shape=(50,37,1)),\n    layers.Conv2D(32, kernel_size=(3,3), activation='relu'),   #The Conv2D has a kernel_size of (3,3) that is weight and height of 3\n    layers.MaxPooling2D(pool_size = (2,2)),\n    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),   #The activation function is relu, therefore 0 will be returned if any negative input is received\n    layers.MaxPooling2D(pool_size = (2,2)),      #Has a pool size of (2,2) to further reduce the spatial information by half.\n    layers.Flatten(),\n    layers.Dropout(0.5),                         #The dropout is set at 0.5, that is to regularize the data and dropout 50% during training to avoid overfitting the training data.\n    layers.Dense(256, activation = 'relu'),\n    layers.Dense(output_classes, activation=\"softmax\"),  \n  ])\n\nmodel.compile(optimizer='adam',\n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n\n#Training the model\nmodel.fit(X_train, y_train, epochs=100, batch_size=128)\n\nprint(\"\\n\", \"done in %0.3fs\" % (time() - t0))","metadata":{"execution":{"iopub.status.busy":"2022-11-09T01:42:38.412832Z","iopub.execute_input":"2022-11-09T01:42:38.413095Z","iopub.status.idle":"2022-11-09T01:43:56.460962Z","shell.execute_reply.started":"2022-11-09T01:42:38.413065Z","shell.execute_reply":"2022-11-09T01:43:56.459965Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Fitting the CNN to the training set\n","output_type":"stream"},{"name":"stderr","text":"2022-11-09 01:42:45.460437: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n2022-11-09 01:42:45.674984: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n/opt/conda/lib/python3.7/site-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n8/8 [==============================] - 2s 95ms/step - loss: 19.8415 - accuracy: 0.2329\nEpoch 2/100\n8/8 [==============================] - 1s 83ms/step - loss: 2.0241 - accuracy: 0.2950\nEpoch 3/100\n8/8 [==============================] - 1s 83ms/step - loss: 1.5691 - accuracy: 0.4420\nEpoch 4/100\n8/8 [==============================] - 1s 84ms/step - loss: 1.4136 - accuracy: 0.5104\nEpoch 5/100\n8/8 [==============================] - 1s 86ms/step - loss: 1.2094 - accuracy: 0.5694\nEpoch 6/100\n8/8 [==============================] - 1s 85ms/step - loss: 1.0157 - accuracy: 0.6542\nEpoch 7/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.8368 - accuracy: 0.7226\nEpoch 8/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.7952 - accuracy: 0.7246\nEpoch 9/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.6827 - accuracy: 0.7640\nEpoch 10/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.5716 - accuracy: 0.7981\nEpoch 11/100\n8/8 [==============================] - 1s 87ms/step - loss: 0.5695 - accuracy: 0.8075\nEpoch 12/100\n8/8 [==============================] - 1s 166ms/step - loss: 0.5102 - accuracy: 0.8282\nEpoch 13/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.4762 - accuracy: 0.8499\nEpoch 14/100\n8/8 [==============================] - 1s 86ms/step - loss: 0.4064 - accuracy: 0.8696\nEpoch 15/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.3848 - accuracy: 0.8551\nEpoch 16/100\n8/8 [==============================] - 1s 92ms/step - loss: 0.3841 - accuracy: 0.8634\nEpoch 17/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.3587 - accuracy: 0.8851\nEpoch 18/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.3030 - accuracy: 0.8975\nEpoch 19/100\n8/8 [==============================] - 1s 103ms/step - loss: 0.2417 - accuracy: 0.9151\nEpoch 20/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.2516 - accuracy: 0.9151\nEpoch 21/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.2165 - accuracy: 0.9317\nEpoch 22/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.2156 - accuracy: 0.9296\nEpoch 23/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.2333 - accuracy: 0.9203\nEpoch 24/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.2136 - accuracy: 0.9244\nEpoch 25/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.1901 - accuracy: 0.9410\nEpoch 26/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.1924 - accuracy: 0.9441\nEpoch 27/100\n8/8 [==============================] - 1s 112ms/step - loss: 0.1494 - accuracy: 0.9524\nEpoch 28/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.1628 - accuracy: 0.9431\nEpoch 29/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.1624 - accuracy: 0.9503\nEpoch 30/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.1442 - accuracy: 0.9451\nEpoch 31/100\n8/8 [==============================] - 1s 86ms/step - loss: 0.1090 - accuracy: 0.9648\nEpoch 32/100\n8/8 [==============================] - 1s 95ms/step - loss: 0.1051 - accuracy: 0.9669\nEpoch 33/100\n8/8 [==============================] - 1s 88ms/step - loss: 0.1429 - accuracy: 0.9565\nEpoch 34/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.1361 - accuracy: 0.9658\nEpoch 35/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.1118 - accuracy: 0.9607\nEpoch 36/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.1250 - accuracy: 0.9545\nEpoch 37/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.1044 - accuracy: 0.9689\nEpoch 38/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0811 - accuracy: 0.9814\nEpoch 39/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.1112 - accuracy: 0.9638\nEpoch 40/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0814 - accuracy: 0.9741\nEpoch 41/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.0895 - accuracy: 0.9720\nEpoch 42/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0711 - accuracy: 0.9814\nEpoch 43/100\n8/8 [==============================] - 1s 81ms/step - loss: 0.0863 - accuracy: 0.9752\nEpoch 44/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0618 - accuracy: 0.9803\nEpoch 45/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0548 - accuracy: 0.9855\nEpoch 46/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0738 - accuracy: 0.9752\nEpoch 47/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.0816 - accuracy: 0.9752\nEpoch 48/100\n8/8 [==============================] - 1s 92ms/step - loss: 0.0716 - accuracy: 0.9803\nEpoch 49/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0571 - accuracy: 0.9834\nEpoch 50/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0548 - accuracy: 0.9855\nEpoch 51/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0655 - accuracy: 0.9741\nEpoch 52/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.0689 - accuracy: 0.9793\nEpoch 53/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.0696 - accuracy: 0.9710\nEpoch 54/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0772 - accuracy: 0.9772\nEpoch 55/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0494 - accuracy: 0.9824\nEpoch 56/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0622 - accuracy: 0.9793\nEpoch 57/100\n8/8 [==============================] - 1s 170ms/step - loss: 0.0392 - accuracy: 0.9896\nEpoch 58/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0667 - accuracy: 0.9762\nEpoch 59/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0292 - accuracy: 0.9938\nEpoch 60/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0393 - accuracy: 0.9865\nEpoch 61/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0438 - accuracy: 0.9876\nEpoch 62/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0526 - accuracy: 0.9834\nEpoch 63/100\n8/8 [==============================] - 1s 89ms/step - loss: 0.0419 - accuracy: 0.9855\nEpoch 64/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0457 - accuracy: 0.9865\nEpoch 65/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.0396 - accuracy: 0.9917\nEpoch 66/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0397 - accuracy: 0.9865\nEpoch 67/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0434 - accuracy: 0.9865\nEpoch 68/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0321 - accuracy: 0.9928\nEpoch 69/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.0429 - accuracy: 0.9855\nEpoch 70/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0314 - accuracy: 0.9896\nEpoch 71/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0292 - accuracy: 0.9917\nEpoch 72/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0228 - accuracy: 0.9938\nEpoch 73/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0438 - accuracy: 0.9834\nEpoch 74/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0475 - accuracy: 0.9865\nEpoch 75/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0378 - accuracy: 0.9845\nEpoch 76/100\n8/8 [==============================] - 1s 81ms/step - loss: 0.0428 - accuracy: 0.9855\nEpoch 77/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0329 - accuracy: 0.9896\nEpoch 78/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0304 - accuracy: 0.9917\nEpoch 79/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0206 - accuracy: 0.9948\nEpoch 80/100\n8/8 [==============================] - 1s 92ms/step - loss: 0.0104 - accuracy: 0.9969\nEpoch 81/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0214 - accuracy: 0.9896\nEpoch 82/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0303 - accuracy: 0.9896\nEpoch 83/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0199 - accuracy: 0.9938\nEpoch 84/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0407 - accuracy: 0.9865\nEpoch 85/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0396 - accuracy: 0.9855\nEpoch 86/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0317 - accuracy: 0.9896\nEpoch 87/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0282 - accuracy: 0.9886\nEpoch 88/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0333 - accuracy: 0.9917\nEpoch 89/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0188 - accuracy: 0.9938\nEpoch 90/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.0288 - accuracy: 0.9928\nEpoch 91/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0200 - accuracy: 0.9938\nEpoch 92/100\n8/8 [==============================] - 1s 82ms/step - loss: 0.0231 - accuracy: 0.9907\nEpoch 93/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0227 - accuracy: 0.9917\nEpoch 94/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0286 - accuracy: 0.9896\nEpoch 95/100\n8/8 [==============================] - 1s 86ms/step - loss: 0.0235 - accuracy: 0.9948\nEpoch 96/100\n8/8 [==============================] - 1s 95ms/step - loss: 0.0343 - accuracy: 0.9876\nEpoch 97/100\n8/8 [==============================] - 1s 88ms/step - loss: 0.0388 - accuracy: 0.9886\nEpoch 98/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0240 - accuracy: 0.9938\nEpoch 99/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0282 - accuracy: 0.9896\nEpoch 100/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.0135 - accuracy: 0.9959\n\n done in 71.046s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Evaluating the trained model**","metadata":{}},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n\nprint('\\n Test accuracy:', test_acc)","metadata":{"execution":{"iopub.status.busy":"2022-11-09T01:43:56.462434Z","iopub.execute_input":"2022-11-09T01:43:56.463284Z","iopub.status.idle":"2022-11-09T01:43:56.823343Z","shell.execute_reply.started":"2022-11-09T01:43:56.463240Z","shell.execute_reply":"2022-11-09T01:43:56.822288Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"11/11 - 0s - loss: 0.5874 - accuracy: 0.8851\n\n Test accuracy: 0.8850931525230408\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> **Result: With the chosen parameters of 100 Epochs and Batch_size of 128 in the deep CNN, we have an accuracy of 88%.**","metadata":{}}]}