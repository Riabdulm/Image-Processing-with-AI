{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importation of needed Libraries**","metadata":{}},{"cell_type":"code","source":"from time import time\nimport logging\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\n\nprint(__doc__)\n\n# Display progress logs on stdout\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')","metadata":{"execution":{"iopub.status.busy":"2022-11-08T23:18:22.543831Z","iopub.execute_input":"2022-11-08T23:18:22.544539Z","iopub.status.idle":"2022-11-08T23:18:23.889399Z","shell.execute_reply.started":"2022-11-08T23:18:22.544402Z","shell.execute_reply":"2022-11-08T23:18:23.888494Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Automatically created module for IPython interactive environment\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Dataset Importaion and Processing**\n\nThe dataset - lfw_people were imported from sklearn.datasets. The label to predict is the identity of the individuals in the image (image recognition).","metadata":{}},{"cell_type":"code","source":"# Downloading and loading the dataset as numpy arrays\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n\n\n# introspect the images arrays to find the shapes (for plotting)\nn_samples, h, w = lfw_people.images.shape\n\n# for machine learning we use the 2 data directly (as relative pixel positions info is ignored by this model)\nX = lfw_people.data\nn_features = X.shape[1]\n\n# the label to predict is the id of the person\ny = lfw_people.target\ntarget_names = lfw_people.target_names\nn_classes = target_names.shape[0]\n\nprint(\"Total dataset size:\")\nprint(\"n_samples: %d\" % n_samples)\nprint(\"n_features: %d\" % n_features)\nprint(\"n_classes: %d\" % n_classes)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T23:18:23.891320Z","iopub.execute_input":"2022-11-08T23:18:23.892075Z","iopub.status.idle":"2022-11-08T23:18:54.623558Z","shell.execute_reply.started":"2022-11-08T23:18:23.892028Z","shell.execute_reply":"2022-11-08T23:18:54.622703Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Total dataset size:\nn_samples: 1288\nn_features: 1850\nn_classes: 7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Splitting data into a training set and a test set with test_size of 25%, and printing the resulting input variables X**","metadata":{}},{"cell_type":"code","source":"# split into a training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\nprint(X_test.shape)\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T23:18:54.625070Z","iopub.execute_input":"2022-11-08T23:18:54.625455Z","iopub.status.idle":"2022-11-08T23:18:54.638378Z","shell.execute_reply.started":"2022-11-08T23:18:54.625408Z","shell.execute_reply":"2022-11-08T23:18:54.637042Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(322, 1850)\n(966, 1850)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Setting parameters for the learner (Deep Convolutional Neural Network - CNN).**","metadata":{}},{"cell_type":"code","source":"#Import needed libraries\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nX_train = X_train.reshape(len(X_train), 50, 37, 1)        #50 * 37 to add up to 1850\nX_test = X_test.reshape(len(X_test), 50, 37, 1)\n\nprint(\"Fitting the CNN to the training set\")\n\nt0 = time()\n \noutput_classes = 7\n\nmodel=keras.Sequential([\n    keras.Input(shape=(50,37,1)),\n    layers.Conv2D(32, kernel_size=(3,3), activation='relu'),   #The Conv2D has a kernel_size of (3,3) that is weight and height of 3\n    layers.MaxPooling2D(pool_size = (2,2)),\n    layers.Conv2D(64, kernel_size=(3,3), activation='relu'),   #The activation function is relu, therefore 0 will be returned if any negative input is received\n    layers.MaxPooling2D(pool_size = (2,2)),      #Has a pool size of (2,2) to further reduce the spatial information by half.\n    layers.Flatten(),\n    layers.Dropout(0.5),                         #The dropout is set at 0.5, that is to regularize the data and dropout 50% during training to avoid overfitting the training data.\n    layers.Dense(256, activation = 'relu'),\n    layers.Dense(output_classes, activation=\"softmax\"),  \n  ])\n\nmodel.compile(optimizer='adam',\n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n\n#Training the model\nmodel.fit(X_train, y_train, epochs=100, batch_size=128)\n\nprint(\"\\n\", \"done in %0.3fs\" % (time() - t0))","metadata":{"execution":{"iopub.status.busy":"2022-11-08T23:18:54.640513Z","iopub.execute_input":"2022-11-08T23:18:54.640821Z","iopub.status.idle":"2022-11-08T23:20:06.182652Z","shell.execute_reply.started":"2022-11-08T23:18:54.640780Z","shell.execute_reply":"2022-11-08T23:20:06.181169Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Fitting the CNN to the training set\n","output_type":"stream"},{"name":"stderr","text":"2022-11-08 23:19:00.693454: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n2022-11-08 23:19:00.890568: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n","output_type":"stream"},{"name":"stdout","text":"8/8 [==============================] - 1s 78ms/step - loss: 58.2871 - accuracy: 0.2433\nEpoch 2/100\n8/8 [==============================] - 1s 76ms/step - loss: 3.9025 - accuracy: 0.3230\nEpoch 3/100\n8/8 [==============================] - 1s 77ms/step - loss: 1.5647 - accuracy: 0.4586\nEpoch 4/100\n8/8 [==============================] - 1s 76ms/step - loss: 1.3241 - accuracy: 0.5497\nEpoch 5/100\n8/8 [==============================] - 1s 79ms/step - loss: 1.2337 - accuracy: 0.5745\nEpoch 6/100\n8/8 [==============================] - 1s 79ms/step - loss: 1.0498 - accuracy: 0.6398\nEpoch 7/100\n8/8 [==============================] - 1s 78ms/step - loss: 1.0546 - accuracy: 0.6201\nEpoch 8/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.9012 - accuracy: 0.6915\nEpoch 9/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.8812 - accuracy: 0.6946\nEpoch 10/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.7199 - accuracy: 0.7412\nEpoch 11/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.8189 - accuracy: 0.7288\nEpoch 12/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.7093 - accuracy: 0.7516\nEpoch 13/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.5850 - accuracy: 0.8168\nEpoch 14/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.6194 - accuracy: 0.7805\nEpoch 15/100\n8/8 [==============================] - 1s 85ms/step - loss: 0.5661 - accuracy: 0.7919\nEpoch 16/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.5126 - accuracy: 0.8251\nEpoch 17/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.4966 - accuracy: 0.8271\nEpoch 18/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.4558 - accuracy: 0.8313\nEpoch 19/100\n8/8 [==============================] - 1s 78ms/step - loss: 0.4049 - accuracy: 0.8675\nEpoch 20/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.3831 - accuracy: 0.8592\nEpoch 21/100\n8/8 [==============================] - 1s 79ms/step - loss: 0.3921 - accuracy: 0.8613\nEpoch 22/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.3499 - accuracy: 0.8913\nEpoch 23/100\n8/8 [==============================] - 1s 86ms/step - loss: 0.3110 - accuracy: 0.8965\nEpoch 24/100\n8/8 [==============================] - 1s 104ms/step - loss: 0.3212 - accuracy: 0.8986\nEpoch 25/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.3507 - accuracy: 0.8820\nEpoch 26/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.3446 - accuracy: 0.8923\nEpoch 27/100\n8/8 [==============================] - 1s 78ms/step - loss: 0.4164 - accuracy: 0.8602\nEpoch 28/100\n8/8 [==============================] - 1s 78ms/step - loss: 0.2645 - accuracy: 0.9089\nEpoch 29/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.3030 - accuracy: 0.8996\nEpoch 30/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.2836 - accuracy: 0.9027\nEpoch 31/100\n8/8 [==============================] - 1s 102ms/step - loss: 0.2461 - accuracy: 0.9151\nEpoch 32/100\n8/8 [==============================] - 1s 154ms/step - loss: 0.2506 - accuracy: 0.9120\nEpoch 33/100\n8/8 [==============================] - 1s 78ms/step - loss: 0.2509 - accuracy: 0.9151\nEpoch 34/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.2653 - accuracy: 0.8986\nEpoch 35/100\n8/8 [==============================] - 1s 78ms/step - loss: 0.2960 - accuracy: 0.9099\nEpoch 36/100\n8/8 [==============================] - 1s 78ms/step - loss: 0.2857 - accuracy: 0.9017\nEpoch 37/100\n8/8 [==============================] - 1s 79ms/step - loss: 0.2649 - accuracy: 0.9058\nEpoch 38/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.2795 - accuracy: 0.9120\nEpoch 39/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.2246 - accuracy: 0.9234\nEpoch 40/100\n8/8 [==============================] - 1s 83ms/step - loss: 0.2354 - accuracy: 0.9203\nEpoch 41/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.2148 - accuracy: 0.9244\nEpoch 42/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.1814 - accuracy: 0.9389\nEpoch 43/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.1916 - accuracy: 0.9306\nEpoch 44/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.1841 - accuracy: 0.9400\nEpoch 45/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.1664 - accuracy: 0.9462\nEpoch 46/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.1353 - accuracy: 0.9586\nEpoch 47/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.1279 - accuracy: 0.9565\nEpoch 48/100\n8/8 [==============================] - 1s 88ms/step - loss: 0.2027 - accuracy: 0.9358\nEpoch 49/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.1551 - accuracy: 0.9565\nEpoch 50/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.1484 - accuracy: 0.9462\nEpoch 51/100\n8/8 [==============================] - 1s 79ms/step - loss: 0.1238 - accuracy: 0.9534\nEpoch 52/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.1287 - accuracy: 0.9586\nEpoch 53/100\n8/8 [==============================] - 1s 75ms/step - loss: 0.1285 - accuracy: 0.9482\nEpoch 54/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.1478 - accuracy: 0.9524\nEpoch 55/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.1033 - accuracy: 0.9720\nEpoch 56/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.1253 - accuracy: 0.9586\nEpoch 57/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.1081 - accuracy: 0.9627\nEpoch 58/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.1288 - accuracy: 0.9534\nEpoch 59/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0849 - accuracy: 0.9762\nEpoch 60/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.1031 - accuracy: 0.9627\nEpoch 61/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.1114 - accuracy: 0.9596\nEpoch 62/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.1204 - accuracy: 0.9576\nEpoch 63/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.1032 - accuracy: 0.9658\nEpoch 64/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0862 - accuracy: 0.9741\nEpoch 65/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0917 - accuracy: 0.9679\nEpoch 66/100\n8/8 [==============================] - 1s 88ms/step - loss: 0.0890 - accuracy: 0.9710\nEpoch 67/100\n8/8 [==============================] - 1s 80ms/step - loss: 0.1022 - accuracy: 0.9710\nEpoch 68/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0907 - accuracy: 0.9710\nEpoch 69/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0783 - accuracy: 0.9741\nEpoch 70/100\n8/8 [==============================] - 1s 78ms/step - loss: 0.0679 - accuracy: 0.9803\nEpoch 71/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0719 - accuracy: 0.9803\nEpoch 72/100\n8/8 [==============================] - 1s 78ms/step - loss: 0.1101 - accuracy: 0.9638\nEpoch 73/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0861 - accuracy: 0.9731\nEpoch 74/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0693 - accuracy: 0.9772\nEpoch 75/100\n8/8 [==============================] - 1s 75ms/step - loss: 0.0886 - accuracy: 0.9679\nEpoch 76/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0632 - accuracy: 0.9803\nEpoch 77/100\n8/8 [==============================] - 1s 78ms/step - loss: 0.0670 - accuracy: 0.9814\nEpoch 78/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0815 - accuracy: 0.9700\nEpoch 79/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0883 - accuracy: 0.9700\nEpoch 80/100\n8/8 [==============================] - 1s 114ms/step - loss: 0.0782 - accuracy: 0.9752\nEpoch 81/100\n8/8 [==============================] - 1s 123ms/step - loss: 0.0645 - accuracy: 0.9783\nEpoch 82/100\n8/8 [==============================] - 1s 87ms/step - loss: 0.0793 - accuracy: 0.9700\nEpoch 83/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0492 - accuracy: 0.9855\nEpoch 84/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0617 - accuracy: 0.9814\nEpoch 85/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0695 - accuracy: 0.9772\nEpoch 86/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0419 - accuracy: 0.9865\nEpoch 87/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0637 - accuracy: 0.9783\nEpoch 88/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0519 - accuracy: 0.9814\nEpoch 89/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0566 - accuracy: 0.9855\nEpoch 90/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0918 - accuracy: 0.9679\nEpoch 91/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0535 - accuracy: 0.9793\nEpoch 92/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0386 - accuracy: 0.9896\nEpoch 93/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0509 - accuracy: 0.9834\nEpoch 94/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0378 - accuracy: 0.9907\nEpoch 95/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0597 - accuracy: 0.9741\nEpoch 96/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0577 - accuracy: 0.9824\nEpoch 97/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0433 - accuracy: 0.9896\nEpoch 98/100\n8/8 [==============================] - 1s 77ms/step - loss: 0.0779 - accuracy: 0.9720\nEpoch 99/100\n8/8 [==============================] - 1s 76ms/step - loss: 0.0664 - accuracy: 0.9783\nEpoch 100/100\n8/8 [==============================] - 1s 84ms/step - loss: 0.0549 - accuracy: 0.9855\n\n done in 65.531s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> **Result: With the chosen parameters of 100 Epochs and Batch_size of 128 in the deep CNN, we have an accuracy of 98%.**","metadata":{}}]}